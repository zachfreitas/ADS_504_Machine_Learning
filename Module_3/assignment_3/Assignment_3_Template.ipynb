{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Assignment #3 Template",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zachfreitas/ADS_504_Machine_Learning/blob/main/Module_3/assignment_3/Assignment_3_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SqDTDH6H2go"
      },
      "outputs": [],
      "source": [
        "# All IMPORTS you may need! \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KNN on Audio Drum Data**\n",
        "\n",
        "One key to designing a k-nearest neighbor model is a good choice of the distance metric. By\n",
        "working through these examples (in order), you will overcome a few challenges in applying distances\n",
        "to datasets. Use scikit-learn’s neighbors. `KNeighborsClassifier` to train a classifier on each of the\n",
        "provided datasets.\n",
        "For all three datasets, because they are small in size, you will use most of the data for training.\n",
        "For all model, do a cross-validation split using:\n",
        "\n",
        "`X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)`\n",
        "\n",
        "Load the Drum sounds dataset. Remember that these data are vectors, and each value is the\n",
        "amount of power (signal intensity) at that particular frequency. Use the distance metric euclidean.\n",
        "Next, staying with the Euclidean metric, increase the number of neighbors from1 to 9, only using\n",
        "odd numbers. Save the accuracy at each value of k, and you will be plotting them later. Change\n",
        "the distance metric to Manhattan distance. Again, vary the number of numbers and plot results\n",
        "for accuracy using both distance metrics on the Drum dataset. Plot both the training and test set\n",
        "errors as below."
      ],
      "metadata": {
        "id": "w3Zeapb6qWUM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*2.1 Euclidean Distance*"
      ],
      "metadata": {
        "id": "PMnMRvNHr0iE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Audio dataset  here\n",
        "audio_df ="
      ],
      "metadata": {
        "id": "sDLOPw0OqX8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the data into train and test, random state= 42 and 90% of data for training"
      ],
      "metadata": {
        "id": "MyQQcr-HqolM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*KNN with k ∈ [1, 9]*"
      ],
      "metadata": {
        "id": "1I4cIzHIsSvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This function is supposed to create and test a KNN model\n",
        "\n",
        "def k_neighbors(xtrain, ytrain, xtest, ytest, kvalues, metric):\n",
        "  knn_accuracy = []\n",
        "  clfs = []\n",
        "  for i in kvalues:\n",
        "    clf = KNeighborsClassifier(metric=metric, n_neighbors=i).fit(xtrain, ytrain)\n",
        "    clf_train_pred = clf.predict(xtrain)\n",
        "    clf_test_pred = clf.predict(xtest)\n",
        "    clfs.append(clf)\n",
        "    knn_accuracy.append({'k values': i,\n",
        "    'Training Accuracy':accuracy_score(clf_train_pred,ytrain),\n",
        "    'Test Accuracy': accuracy_score(clf_test_pred,ytest)})\n",
        "  return pd.DataFrame(knn_accuracy), clfs"
      ],
      "metadata": {
        "id": "sy4RiVwMrG4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*KNN using L2 norm*"
      ],
      "metadata": {
        "id": "eU4lO45kskot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn_euc_acc, knn_euc_clfs = k_neighbors(X_train, y_train, X_test, y_test,range(), '')   #Define the range of 1 to 10 and the type as euclidean\n",
        "display(knn_euc_acc)"
      ],
      "metadata": {
        "id": "YQOmow_Zrcm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K*NN L2 norm with k ∈ [0, 9] Accuracy plot*"
      ],
      "metadata": {
        "id": "ap1gem3gswuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(knn_euc_acc['k values'], knn_euc_acc['Training Accuracy'], '--',linewidth=2, label='Training Accuracy')\n",
        "# Repeat the same plot as above but this time for test accutracy\n",
        "plt.xlabel('k Neighbors')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('KNN Accuracy - L2 Norm')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LAa8Ogw3rlMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.2 Manhattan Distance**\n",
        "\n",
        "*KNN using L1 norm*"
      ],
      "metadata": {
        "id": "6aV-Dpg6tLhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Repeat same model this time with 'manhatan'"
      ],
      "metadata": {
        "id": "BvKNMcMvrrYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN L1 norm with k ∈ [0, 9] Accuracy plot here"
      ],
      "metadata": {
        "id": "SOVOtacVru6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3 KNN on Animal Shelter Data** \n",
        "\n",
        "Next, you will try the animal shelter data. To convert these categorical features to a vector, use\n",
        "`enc = OneHotEncoder(sparse=‘False’)`. Read the documentation on what `oneHotEncoder` is doing,\n",
        "and note how large the transformed data are. Plot a graph of accuracy using k varying from 1 to\n",
        "9 and using Cosine as the distance."
      ],
      "metadata": {
        "id": "sJflLXVOtgTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the Shelter dataset\n",
        "shelter_df = "
      ],
      "metadata": {
        "id": "nnX3YU4Or-nQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop null values on Anima Data\n",
        "\n",
        "# Define y as 'OutcomeType' and X as {'Name', 'DateTime', 'AnimalType', 'SexuponOutcome','AgeuponOutcome', 'Breed', 'Color'}\n",
        "\n",
        "\n",
        "# one-hot encode\n",
        "ohe = OneHotEncoder(sparse=False).fit(x[['Name', 'AnimalType', 'SexuponOutcome',\n",
        "'Breed', 'Color']])\n",
        "\n",
        "# ordinal\n",
        "ord = OrdinalEncoder().fit(x[['DateTime', 'AgeuponOutcome']])\n",
        "cat_df = pd.DataFrame(ohe.transform(x[['Name', 'AnimalType', 'SexuponOutcome',\n",
        "'Breed', 'Color']]),\n",
        "columns=ohe.get_feature_names(['Name', 'AnimalType',\n",
        "'SexuponOutcome', 'Breed','Color']))\n",
        "ord_df = pd.DataFrame(ord.transform(x[['DateTime', 'AgeuponOutcome']]),\n",
        "columns=['DateTime', 'AgeuponOutcome'])\n",
        "\n",
        "# concat the categoricals and ordinals\n",
        "x = pd.concat([cat_df, ord_df], axis=1)\n",
        "le = LabelEncoder()\n",
        "y = le.fit(y).transform(y)\n",
        "\n",
        "# split data to 90% for training with the random state of 42\n",
        "\n"
      ],
      "metadata": {
        "id": "V4QU0prGsNSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Repeat the same strategy above. Design the KNN in range of 1 to 10 with skip of 2 \n",
        "# this time use 'Cosine'"
      ],
      "metadata": {
        "id": "KCTwHuRTuTuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Same as previous steps, KNN Cosine Similarity with k ∈ [0, 9] Accuracy plot"
      ],
      "metadata": {
        "id": "0w5qafw-uhMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4 KNN on Text Data**\n",
        "\n",
        "Finally, load the text data using count_hamilton.csv. You will again use k-nearest neighbors to\n",
        "build a classifier, varying the number of neighbors from 1 to 9. Use both Cosine and Euclidean\n",
        "distance to plot accuracy as the number of neighbors increases."
      ],
      "metadata": {
        "id": "g1ueXJ65ulKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read text data\n",
        "text_df = \n"
      ],
      "metadata": {
        "id": "ZTPNB9PjsffG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop meta_author and meta_title\n",
        "# Use label encoder as you did in previous assignment and create 90% of data for training in random state of 42\n"
      ],
      "metadata": {
        "id": "JCLG_lZNutUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.1 Euclidean Distance**\n",
        "\n",
        "KNN L2 norm"
      ],
      "metadata": {
        "id": "XwIW0uZYu9hD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Same strategy as before, create euclidean for the range of K"
      ],
      "metadata": {
        "id": "DuFhBdl0u886"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN L2 norm with k ∈ [0, 9] Accuracy plot"
      ],
      "metadata": {
        "id": "HH9xoHzZvHKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.2 Cosine**\n",
        "\n",
        "KNN Cosine similarity"
      ],
      "metadata": {
        "id": "IA3bx7lavOHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Same strategy as before, create cosine for the range of K"
      ],
      "metadata": {
        "id": "7SCp-AbsvQm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN L2 norm with k ∈ [0, 9] Accuracy plot"
      ],
      "metadata": {
        "id": "Zjz7FhkyvQ4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5 Perceptron Implementation.**\n",
        "\n",
        "Load the audio (Drum) dataset. Make sure you have plus and minus ones for labels. For example,\n",
        "you can modify the labels like this:\n",
        "\n",
        "```\n",
        "y = le.transform(labels)\n",
        "y[y==0] = -1\n",
        "```\n",
        "\n",
        "Write the following functions:\n",
        "\n",
        "`predict_perceptron(X,w)`\n",
        "\n",
        "This takes a dataset and a weight vector and returns all the predictions that would be made by a\n",
        "perceptron.\n",
        "\n",
        "`train_perceptron(X,w)`\n",
        "\n",
        "Returns w, the trained weight vector. This will take the form of a for loop over all the data points,\n",
        "checking against the pseudocode in the text.\n",
        "Train and test your perceptron using the audio (Drum) dataset. In addition, use scikit-learn’s\n",
        "perceptron classifier and compare. Verify that both your implementation and the built-in one are\n",
        "obtaining similar accuracy values."
      ],
      "metadata": {
        "id": "hDlybT9ivYSh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perceptron Implementation"
      ],
      "metadata": {
        "id": "CO-meaDitVHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create X and y (label_text). This time the encoding is different and is between -1 and 1 so wherever y is equal to 0, convert it to -1\n"
      ],
      "metadata": {
        "id": "b_bZOLmqtYX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing Perceptron Classifier using python/numpy"
      ],
      "metadata": {
        "id": "PieXolDmwIRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PerceptronClassifier():\n",
        "  def __init__(self, maxiter):\n",
        "    # hyperparameter\n",
        "    self.maxiter = maxiter\n",
        "  def train_perceptron(self, X, y):\n",
        "    # initialize weights, bias\n",
        "    self.w = np.zeros(X.shape[1])\n",
        "    self.b = 0\n",
        "    for i in range(self.maxiter):\n",
        "      for j in range(X.shape[0]):\n",
        "        a = sum(self.w * X.iloc[j]) + self.b\n",
        "        if y[j] * a <= 0:\n",
        "          # update weights\n",
        "          self.w += y[j] * X.iloc[j]\n",
        "          self.b += y[j]\n",
        "    # return trained weights, bias\n",
        "    return self.w, self.b\n",
        "  def predict_perceptron(self, X):\n",
        "    a = [sum(self.w * x) + self.b for i, x in X.iterrows()]\n",
        "    return np.sign(a).astype(int)"
      ],
      "metadata": {
        "id": "qr3igthKteKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implemented Perceptron and predictions"
      ],
      "metadata": {
        "id": "5_nQzZbkwKsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "perc = PerceptronClassifier(1)\n",
        "_, _ = perc.train_perceptron(X_train, y_train)\n",
        "\n",
        "perc_cm = confusion_matrix(y_test, perc.predict_perceptron(X_test))\n",
        "pd.DataFrame(perc_cm, index=aud_labels, columns=aud_labels)"
      ],
      "metadata": {
        "id": "u76Q1efAtwCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Implemented Perceptron Accuracy %2.2f ' % accuracy_score(y_test, perc.predict_perceptron(X_test)))"
      ],
      "metadata": {
        "id": "8DiqcFExt0wK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scikit-Learn Perceptron and predictions"
      ],
      "metadata": {
        "id": "FiTyx1iLwQvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sk_perc = Perceptron(max_iter=1).fit(X_train, y_train)\n",
        "\n",
        "sk_perc_cm = confusion_matrix(y_test, sk_perc.predict(X_test))\n",
        "pd.DataFrame(sk_perc_cm, index=aud_labels, columns=aud_labels)"
      ],
      "metadata": {
        "id": "_SpvU-_Bt5ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Scikit-Learn Perceptron Accuracy %2.2f ' % accuracy_score(y_test,sk_perc.predict(X_test)))"
      ],
      "metadata": {
        "id": "Qeo4hJe_t_bF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}