{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sample Code",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zachfreitas/ADS_504_Machine_Learning/blob/main/Module_2/assignment_2/Sample_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sjsKUThj2kQ"
      },
      "outputs": [],
      "source": [
        "# These IMPORTs will be needed :)\n",
        "\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pylab as pylab\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import tree\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load and understand  Data**"
      ],
      "metadata": {
        "id": "UX3d-vtYmA-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(' ')  #Read the data here\n",
        "data.describe()"
      ],
      "metadata": {
        "id": "Y5G0091el8_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "or-U5bInmZUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this line drops any rows with missing data\n",
        "cleaned_data = data.dropna()\n",
        "# here we grab the data we want from pandas\n",
        "X_data = cleaned_data[['AnimalType','SexuponOutcome','AgeuponOutcome']]\n",
        "y_data = cleaned_data[['OutcomeType']]\n",
        "enc = OrdinalEncoder()\n",
        "enc.fit(X_data)\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(y_data)\n",
        "data_categorical = pd.DataFrame(enc.transform(X_data),\n",
        "columns=list(X_data))\n",
        "X=data_categorical\n",
        "y=le.transform(y_data)\n",
        "# Without changing the random state, divide your data into 50% for test and 50% for train\n",
        "X_train, X_test, y_train, y_test = train_test_split( , random_state=42)"
      ],
      "metadata": {
        "id": "AGQXHYhTl9CW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply the model here\n",
        "clf =    #Create your model here\n",
        "clf = clf.fit()   #Fit on training data\n",
        "y_pred = clf.predict(X_test)\n",
        "print('accuracy %2.2f ' % accuracy_score(y_test,y_pred))"
      ],
      "metadata": {
        "id": "ziaMPq6Yl9FB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see the confusion matrix together\n",
        "cm = confusion_matrix(le.inverse_transform(y_test), le.inverse_transform(y_pred))\n",
        "labels=['Adoption', 'Died', 'Euthanasia', 'Transfer']\n",
        "test_results = pd.DataFrame(cm,index=labels,columns=labels)\n",
        "display(test_results)"
      ],
      "metadata": {
        "id": "OEunnLVQl9Hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the decision tree\n",
        "fig,ax = plt.subplots(figsize = (30,30))\n",
        "treeplot = tree.plot_tree(clf, feature_names=['AnimalType','SexuponOutcome','AgeuponOutcome'],\n",
        "class_names = ['Adoption', 'Died', 'Euthanasia', 'Transfer'],ax=ax)"
      ],
      "metadata": {
        "id": "3bGi6vnpmvvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Problem 2.1. Animal Control**"
      ],
      "metadata": {
        "id": "HgxSSRMcnBcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a new decision tree here! Remember this time maxdepth should be 3 (short tree)\n"
      ],
      "metadata": {
        "id": "IL7X4nQem9_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create confusion matrix"
      ],
      "metadata": {
        "id": "s0172SSD_qe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the tree here"
      ],
      "metadata": {
        "id": "2JT6ZkOJ_3Oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Varying Tree Depth using Loop**"
      ],
      "metadata": {
        "id": "Teg8HnRTnS4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_errors = list()\n",
        "test_errors = list()\n",
        "for x in range(3,11):\n",
        "  #Create multiple models here each based on the x variable above\n",
        "  # Store the result of modes in train_erors and test_errors variables\n",
        "\n",
        "# Plot of test and training erros\n",
        "plt.plot(range(3,11),train_errors, label='Train')\n",
        "plt.plot(range(3,11),test_errors, label='Test')\n",
        "plt.legend(loc='upper left')\n",
        "plt.xlabel('Depth parameter')\n",
        "plt.ylabel('Performance')"
      ],
      "metadata": {
        "id": "EPtoNi1Bl9KB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Your conclusion about above graph comes here*\n"
      ],
      "metadata": {
        "id": "6_l-YoTvAlSo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tree Pruning here**"
      ],
      "metadata": {
        "id": "XerpuFurnh44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree_prune =\n",
        "tree_prune =\n",
        "treeplot = tree.plot_tree(tree_prune, feature_names=['AnimalType','SexuponOutcome','AgeuponOutcome'],\n",
        "class_names = ['Adoption', 'Died', 'Euthanasia', 'Transfer'],ax=ax)"
      ],
      "metadata": {
        "id": "70FhDNQbnedx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pruned Accuracy vs. Unpruned**"
      ],
      "metadata": {
        "id": "CMVuWI2xqH2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred4 = tree_prune.predict(X_test)\n",
        "print('accuracy %2.2f ' % accuracy_score(y_test,y_pred4))\n",
        "# Type here your understanding about this comparison\n"
      ],
      "metadata": {
        "id": "SznkL6sQnUaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create two confusion matrices here. The first confusion matrix shows predictions for the pruned tree and the second one \n",
        "# predictions for the unpruned one"
      ],
      "metadata": {
        "id": "XzxFOkecBMnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Data**"
      ],
      "metadata": {
        "id": "TFBgSksFAxlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_data = pd.read_csv() # Read data remember (meta_author will be the target)"
      ],
      "metadata": {
        "id": "o_0SkeqPAw6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the decision tree here Randomstate=42 90% training and 10% testing\n",
        "X= \n",
        "le = preprocessing.LabelEncoder()\n",
        "labels = text_data['meta_author']\n",
        "le.fit(labels)\n",
        "y=le.transform(labels)\n",
        " "
      ],
      "metadata": {
        "id": "gMau_Y9MBfqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 2.2**"
      ],
      "metadata": {
        "id": "wgxdy9zTCABk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a loop of max depth from 1 to 16 similar to previous step and draw the \n",
        "#above mentioned graph"
      ],
      "metadata": {
        "id": "a9lU4j-yBftG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# With a simple code, you can see the frequency of the words\n",
        "text_frequecies = X.sum()\n",
        "text_frequecies.sort_values()\n",
        "display(text_frequecies)\n",
        "kept_words = text_frequecies[text_frequecies<2]\n",
        "# this line (above) first creates a binary vector for each word, telling us if it appears twice or more\n",
        "# in the dataset. it then uses that vector to index into text_frequencies to subset only the data\n",
        "# for which this binary vector evaluates to TRUE. This simple indexing can really help to chop through\n",
        "# a huge pandas dataframe.\n",
        "print(kept_words)\n",
        "small_vocab_X= X [kept_words.index]\n",
        "# notice how kept_words.index is a list of strings, the same you can use to access the headers of X.."
      ],
      "metadata": {
        "id": "cI9VFoZXBfvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now repeat the previous analysis (design model by changing the model depth \n",
        "#from 1 to 16) with smaller word dataset small_vocab_X\n",
        "# Plot the above graph again"
      ],
      "metadata": {
        "id": "wTaqKFxXBfx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Most frequent words**"
      ],
      "metadata": {
        "id": "uvKuBS0UDXQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Same as before create the most frequent words\n",
        "kept_words2 = text_frequecies[text_frequecies>100]\n",
        "# this line (above) first creates a binary vector for each word, telling us if it appears twice or more\n",
        "# in the dataset. it then uses that vector to index into text_frequencies to subset only the data\n",
        "# for which this binary vector evaluates to TRUE. This simple indexing can really help to chop through\n",
        "# a huge pandas dataframe.\n",
        "print(kept_words2)\n",
        "large_vocab_X= X [kept_words2.index]"
      ],
      "metadata": {
        "id": "e8VEmL3cDUzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now repeat the previous analysis (design model by changing the model depth \n",
        "#from 1 to 16) with smaller word dataset large_vocab_X\n",
        "# Plot the above graph again"
      ],
      "metadata": {
        "id": "IjQzLdXqDU2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explain your understanding from the graph"
      ],
      "metadata": {
        "id": "ykQdNwjGDU5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Audio Data**"
      ],
      "metadata": {
        "id": "BRixWIwJD13r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_data = pd.read_csv(). # This time you should drop two columns first: filename and label"
      ],
      "metadata": {
        "id": "kM1R2cTnD0qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Desing Decision tree here 80% training 20% testing"
      ],
      "metadata": {
        "id": "etPJH40UDy7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 2.3**"
      ],
      "metadata": {
        "id": "-ig79qKyERHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now repeat the previous analysis (design model by changing the model depth \n",
        "#from 1 to 16) \n",
        "# Plot the above graph again"
      ],
      "metadata": {
        "id": "bgBKzmZ5Dy9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Draw the decision tree plot with max_depth=5"
      ],
      "metadata": {
        "id": "Qtm6MP9GDy-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dropping a training example from data**"
      ],
      "metadata": {
        "id": "vMHBctXeEhEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_dropped = X.drop(1)\n",
        "y= pd.Series(y)\n",
        "y_drop = y.drop(1)\n",
        "X_train, X_test, y_train, y_test =   #80% training"
      ],
      "metadata": {
        "id": "Gi0lQs0HEaba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sound_tree2 = # model with max_depth = 5 \n",
        "sound_tree2 = \n",
        "plt.subplot(1, 2, 1)\n",
        "treeplot = tree.plot_tree()\n",
        "plt.title(\"Before\")\n",
        "plt.subplot(1, 2, 2)\n",
        "treeplot2 = tree.plot_tree(sound_tree2)\n",
        "plt.title(\"After\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s1eopVbqEm2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = audio_data.drop('label_text',axis=1)\n",
        "# Create data with 50% for training. You need to use one hot encodr "
      ],
      "metadata": {
        "id": "Yn4hvqfTEm4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now repeat the previous analysis (design model by changing the model depth \n",
        "#from 1 to 16) \n",
        "# Plot the above graph again"
      ],
      "metadata": {
        "id": "wbwB0EJAEm6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bad Classifiers**"
      ],
      "metadata": {
        "id": "1r55nIgTFMDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BadClassifier():\n",
        "  def __init__(self):\n",
        "    pd = __import__('pandas')\n",
        "    self.label_counts = pd.Series()\n",
        "  def train(self, y_train):\n",
        "    train_labels = pd.Series(y_train)\n",
        "    label_counts = train_labels.value_counts(normalize=True)\n",
        "    self.label_counts = label_counts.sort_index()\n",
        "  def make_random_predictions(self, X_test):\n",
        "    pred_labels=[]\n",
        "    test_labels = pd.Series(y_test)\n",
        "    test_label_counts = np.random.multinomial(X_test.shape[0],self.label_counts.values)\n",
        "    for count,label in zip (test_label_counts,self.label_counts.index.values):\n",
        "      pred_labels = pred_labels + [label for x in range(0,count)]\n",
        "    np.random.shuffle(pred_labels)\n",
        "    return pred_labels"
      ],
      "metadata": {
        "id": "JYqZV8MCFJ_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bad = BadClassifier()\n",
        "accuracy = list()\n",
        "train_errors = list()\n",
        "test_errors = list()\n",
        "for x in range(1,16):\n",
        "  bad.train(y_train)\n",
        "  y_pred = bad.make_random_predictions(X_test)\n",
        "  accuracy.append()   # Fill this\n",
        "  sound_trees =  # Fill this\n",
        "  sound_trees = # Fill this\n",
        "  train_errors.append()# Fill this\n",
        "  test_errors.append()# Fill this\n",
        "# plotting\n",
        "plt.plot(range(1,16),accuracy, label='Random')\n",
        "plt.plot(range(1,16),train_errors, label='Train')\n",
        "plt.plot(range(1,16),test_errors, label='Test')\n",
        "plt.legend(loc='center right')\n",
        "plt.xlabel('Depth parameter')\n",
        "plt.ylabel('Performance')\n"
      ],
      "metadata": {
        "id": "5ufNtwWiFLXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Repeat above step but this time use only 1% of data for testing"
      ],
      "metadata": {
        "id": "RiFmAmxkFLZ5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}